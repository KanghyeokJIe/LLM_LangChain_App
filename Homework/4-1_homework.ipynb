{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2769de73",
   "metadata": {},
   "source": [
    "## 문제 4-1 : OpenAI에서 Ollama Qwen3로 RAG 시스템 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b66956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 라이브러리 임포트 완료.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings # 변경: HuggingFaceEmbeddings 임포트\n",
    "from langchain_ollama import ChatOllama # 변경: ChatOllama 임포트\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "print(\"모든 라이브러리 임포트 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d4d630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 1. 문서 로딩 → PDF 읽기...\n",
      "  총 39페이지 로드 완료\n"
     ]
    }
   ],
   "source": [
    "print(\"==> 1. 문서 로딩 → PDF 읽기...\")\n",
    "loader = PyPDFLoader('../data/tutorial-korean.pdf')\n",
    "documents = loader.load()\n",
    "print(f\"  총 {len(documents)}페이지 로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da3fea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 2. 문서 분할 → 작은 청크로 나누기\n",
      "  76개 청크 생성 완료\n"
     ]
    }
   ],
   "source": [
    "print(\"==> 2. 문서 분할 → 작은 청크로 나누기\")\n",
    "# 로컬 모델을 위한 최적화\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,  # 변경: 1000 -> 800 (조금 더 작게)\n",
    "    chunk_overlap=150, # 변경: 200 -> 150 (중복 감소)\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"  {len(chunks)}개 청크 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6275ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 3. 벡터화 → 임베딩으로 변환\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-basic-kGdHTiMZ-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2' 임베딩 모델 로드 완료.\n"
     ]
    }
   ],
   "source": [
    "print(\"==> 3. 벡터화 → 임베딩으로 변환\")\n",
    "# 임베딩 모델 변경: OpenAIEmbeddings -> HuggingFaceEmbeddings\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_kwargs={'device': 'cpu'}, # CPU 사용 명시 (GPU가 있다면 'cuda'로 변경 가능)\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "print(f\"  '{EMBEDDING_MODEL_NAME}' 임베딩 모델 로드 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b779c230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 4. 저장 → FAISS 벡터스토어에 저장\n",
      "  FAISS 벡터스토어 저장 완료.\n"
     ]
    }
   ],
   "source": [
    "print(\"==> 4. 저장 → FAISS 벡터스토어에 저장\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "print(\"  FAISS 벡터스토어 저장 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df660eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 5. 검색 → 질문과 유사한 문서 찾기\n",
      "  검색기 설정 완료.\n"
     ]
    }
   ],
   "source": [
    "print(\"===> 5. 검색 → 질문과 유사한 문서 찾기\")\n",
    "# 성능을 위해 검색 결과 수 감소\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}  # 변경: 6 -> 4 (검색 결과 수 감소)\n",
    ")\n",
    "print(\"  검색기 설정 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a7e1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 6. 생성 → LLM으로 답변 생성\n",
      "  Ollama Qwen3 LLM 모델 로드 완료.\n"
     ]
    }
   ],
   "source": [
    "print(\"===> 6. 생성 → LLM으로 답변 생성\")\n",
    "# LLM 모델 변경: ChatOpenAI -> ChatOllama\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen3:1.7b\",\n",
    "    base_url=\"http://localhost:11434\", # Ollama 서버 주소\n",
    "    temperature=0.1,\n",
    "    num_predict=1500  # 변경: max_tokens -> num_predict (Ollama에 맞는 파라미터)\n",
    ")\n",
    "print(\"  Ollama Qwen3 LLM 모델 로드 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f79b5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RAG 체인 설정 및 질문 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4336\\1260895907.py:29: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 질문 ---\n",
      "튜토리얼에 대한 설명을 해 줘\n",
      "\n",
      "--- 답변 ---\n",
      "<think>\n",
      "Okay, let's see. The user is asking for an explanation of the tutorial. The context provided is a bit messy with different sections and numbers. Let me try to parse it.\n",
      "\n",
      "First, the context starts with \"7.4. 중지와 종료\" which seems to be about stopping and ending. Then there's \"8. 독립형 어플리케이션 생성\" and \"9. 애플릿 만들기\" which are sections about creating standalone applications and apps. Then there's \"3.4. 실행하기\" and \"3.5. 클래스 편집하기\" etc., which are about running and editing classes. Finally, there's \"12. 번역을 마치며\" which is about translating and thanking God.\n",
      "\n",
      "The user's question is about the tutorial, so I need to figure out what the tutorial is about based on the context. The main sections mention creating applications and apps, running them, editing classes, compiling, and translating. The tutorial seems to be a guide for developing applications using some programming tools, possibly Java or similar, given the terms like \"애플릿\" (applet) and \"컴파일러\" (compiler).\n",
      "\n",
      "The answer should summarize the tutorial's content. The user might be a beginner learning how to create applications, so the explanation should be clear and cover the main steps: creating standalone apps, making applets, running them, editing classes, compiling, and translating. Also, the context mentions \"T h a n k s  G o d .  I t ' s  a  B l u e J .\" which is a note from the author, possibly indicating the tutorial is in Korean, and the translation is done.\n",
      "\n",
      "So, the answer should mention the tutorial's purpose, the steps involved, and the key topics covered. Make sure to highlight the main sections like creating apps, making applets, running, compiling, and the translation part. Keep it concise but informative.\n",
      "</think>\n",
      "\n",
      "**튜토리얼 설명:**  \n",
      "이 튜토리얼은 애플리케이션 개발을 위한 프로그래밍 기초부터 실무 기술까지 체계적으로 가르쳐주는 내용입니다. 주요 주제는 다음과 같습니다:  \n",
      "\n",
      "1. **독립형 어플리케이션 생성**  \n",
      "   - 프로그래밍 언어(예: Java)를 사용해 독립적인 애플리케이션을 생성하는 방법.  \n",
      "   - 편집기, 컴파일러, 실행 파일 생성 과정 설명.  \n",
      "\n",
      "2. **애플릿 만들기**  \n",
      "   - 웹 브라우저에서 실행 가능한 애플릿 개발 방법.  \n",
      "   - 애플릿 실행 및 편집 기능 소개.  \n",
      "\n",
      "3. **실행 및 컴파일**  \n",
      "   - 애플리케이션 실행, 컴파일 과정, 에러 해결 방법.  \n",
      "\n",
      "4. **번역 및 종료**  \n",
      "   - 튜토리얼의 종료 문장 \"Thank you God. It's a Blue J.\"를 포함한 번역 내용.  \n",
      "\n",
      "**요약:**  \n",
      "이 튜토리얼은 애플리케이션 개발의 기본부터 실무 기술까지 학습할 수 있도록 구성되어 있으며, 애플릿과 독립형 프로그램의 개발 방법, 컴파일 및 실행 과정, 에러 해결 등 핵심 내용을 다루고 있습니다.\n",
      "\n",
      "--- 출처 ---\n",
      "- 페이지: 2, 출처: ../data/tutorial-korean.pdf\n",
      "- 페이지: 1, 출처: ../data/tutorial-korean.pdf\n",
      "- 페이지: 38, 출처: ../data/tutorial-korean.pdf\n",
      "- 페이지: 2, 출처: ../data/tutorial-korean.pdf\n",
      "\n",
      "--- RAG 시스템 실행 완료 ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- RAG 체인 설정 및 질문 시작 ---\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt_template = \"\"\"\n",
    "당신은 질문에 답변하는 친절한 챗봇입니다.\n",
    "다음 문맥(Context)을 사용하여 질문에 답변해 주세요.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RetrievalQA 체인 구성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True, # 답변에 사용된 원본 문서 반환 설정\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "# 예시 질문\n",
    "question = \"튜토리얼에 대한 설명을 해 줘\"\n",
    "result = qa_chain({\"query\": question})\n",
    "\n",
    "print(\"\\n--- 질문 ---\")\n",
    "print(question)\n",
    "print(\"\\n--- 답변 ---\")\n",
    "print(result[\"result\"])\n",
    "print(\"\\n--- 출처 ---\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- 페이지: {doc.metadata.get('page')}, 출처: {doc.metadata.get('source')}\")\n",
    "\n",
    "print(\"\\n--- RAG 시스템 실행 완료 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
